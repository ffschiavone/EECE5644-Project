{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class5_class_reg.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure, show\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float32), df.as_matrix([target]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_columns(df):\n",
    "    with open('../column_mapping.json', 'r') as f:\n",
    "        column_mapping = json.load(f)\n",
    "    # Important columns: YearsProgram, YearsCodedJob, Country, ImportantBenifits, CompanyType\n",
    "    original_columns_to_keep = ['YearsProgram', 'YearsCodedJob', 'Country', 'ImportantBenefits', 'CompanyType', 'Salary']\n",
    "    # def keep_columns(df, original_columns_to_keep):\n",
    "    cleaned_columns_to_keep = []\n",
    "    for original_col in original_columns_to_keep:\n",
    "        cleaned_columns_to_keep += column_mapping[original_col]\n",
    "    return df[cleaned_columns_to_keep].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_read = r\"c:\\Users\\fr23505\\Documents\\machine\\git\\cleaned_data.csv\"\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "df = reduce_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode to a 2D matrix for training\n",
    "# X: data\n",
    "# Y: label\n",
    "x,y = to_xy(df,'Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Neural Network\n",
    "# Squential Network with 3 layers.\n",
    "# Layer 1: 20 nodes using the rectifier\n",
    "# Layer 2: 10 nodes using rectifier\n",
    "# Layer 3: 1 node (regression)\n",
    "# NN using optimization adam\n",
    "\n",
    "# https://keras.io\n",
    "# https://keras.io/layers/core/\n",
    "# https://keras.io/losses/\n",
    "# https://keras.io/optimizers/\n",
    "\n",
    "# Optimizers\n",
    "# SGD - stochastic gradient descent\n",
    "# RMSprop\n",
    "# Adagrad - Adaptive gradient\n",
    "# Adadelta\n",
    "# Adam - Adaptive Moment Estimation\n",
    "# Adamax\n",
    "# Nadam - Nesterov Adam optimizer\n",
    "\n",
    "# Activation Functions\n",
    "# softmax\n",
    "# elu - Exponential Linear Unit\n",
    "# selu - Scaled Exponential Linear Unit\n",
    "# softplus\n",
    "# softsign\n",
    "# relu - rectified linear unit\n",
    "# tanh - hyperbolic tangent\n",
    "# sigmoid\n",
    "# hard_sigmoid\n",
    "# linear\n",
    "\n",
    "num_neurons_1 = len(df.columns);\n",
    "num_neurons_2 = round(len(df.columns)/2);\n",
    "model = Sequential()\n",
    "model.add(Dense(num_neurons_1, input_dim=x.shape[1], activation='linear'))\n",
    "model.add(Dense(num_neurons_2, activation='linear'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop training when a monitored quantity has stopped improving.\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model\n",
    "checkpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\", verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train NN\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=0,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load weights from best model (training above)\n",
    "model.load_weights('best_weights.hdf5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Calculate RMS\n",
    "rms = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"RMS: {}\".format(rms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the chart\n",
    "chart_regression(pred.flatten(),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "chart_regression(pred.flatten(),y_test,sort=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
