{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frank Schiavone\n",
    "EECE5644 Final Project\n",
    "Neural Networks\n",
    "\n",
    "Reference\n",
    "https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class5_class_reg.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure, show\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Douglas\n",
    "def reduce_columns(df):\n",
    "    with open('../column_mapping.json', 'r') as f:\n",
    "        column_mapping = json.load(f)\n",
    "    # Important columns: YearsProgram, YearsCodedJob, Country, ImportantBenifits, CompanyType\n",
    "    original_columns_to_keep = ['YearsProgram', 'YearsCodedJob', 'Country', 'ImportantBenefits', 'CompanyType', 'Salary']\n",
    "    # def keep_columns(df, original_columns_to_keep):\n",
    "    cleaned_columns_to_keep = []\n",
    "    for original_col in original_columns_to_keep:\n",
    "        cleaned_columns_to_keep += column_mapping[original_col]\n",
    "    return df[cleaned_columns_to_keep].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Shuffled Dataset\n",
    "filename_read = r\"c:\\Users\\fr23505\\Documents\\machine\\new_repo\\EECE5644-Project-master\\shuffled.csv\"\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'], index_col='Respondent')\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Create a dataset with reduced Parameters\n",
    "dfr = reduce_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model_layer_1(x_train, y_train, x_test, y_test, activ_func, learn_algo):\n",
    "    # Create the Neural Network Model\n",
    "    # Squential Network with up to 3 layers.\n",
    "    # Layer 1: nFeatures nodes using the rectifier\n",
    "    # Layer n: 1 node (regression)\n",
    "    # NN using optimization adam\n",
    "\n",
    "    # https://keras.io\n",
    "    # https://keras.io/layers/core/\n",
    "    # https://keras.io/losses/\n",
    "    # https://keras.io/optimizers/\n",
    "\n",
    "    # Optimization\n",
    "    # Error function: mean squared error\n",
    "    # Optimizers:\n",
    "    # SGD - stochastic gradient descent\n",
    "    # RMSprop\n",
    "    # Adagrad - Adaptive gradient\n",
    "    # Adadelta\n",
    "    # Adam - Adaptive Moment Estimation\n",
    "    # Adamax\n",
    "    # Nadam - Nesterov Adam optimizer\n",
    "\n",
    "    # Activation Functions\n",
    "    # softmax\n",
    "    # elu - Exponential Linear Unit\n",
    "    # selu - Scaled Exponential Linear Unit\n",
    "    # softplus\n",
    "    # softsign\n",
    "    # relu - rectified linear unit\n",
    "    # tanh - hyperbolic tangent\n",
    "    # sigmoid\n",
    "    # hard_sigmoid\n",
    "    # linear\n",
    "\n",
    "    num_neurons_1 = x_train.shape[1];\n",
    "    num_neurons_2 = round(x_train.shape[1]/2);\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_neurons_1, input_dim=x_train.shape[1], activation=activ_func))\n",
    "    model.add(Dense(num_neurons_2, activation=activ_func))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=learn_algo)\n",
    "    \n",
    "    # Learning Algorithm monitor: Stop training when\n",
    "    # validation loss is less the 1e-3 5 times in a row\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=0, mode='auto')\n",
    "    \n",
    "    # Save weights for NN\n",
    "    checkpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\", verbose=0, save_best_only=True)\n",
    "    \n",
    "    # Train NN\n",
    "    # The model will not be trained on this data.\n",
    "    # epochs=1000, Epoch: # complete iterations of the data set to be learned\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=0,epochs=3000)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model_layer_2(x_train, y_train, x_test, y_test, activ_func, learn_algo):\n",
    "    # Create the Neural Network Model\n",
    "    # Squential Network with up to 3 layers.\n",
    "    # Layer 1: nFeatures nodes using the rectifier\n",
    "    # Layer n: 1 node (regression)\n",
    "    # NN using optimization adam\n",
    "\n",
    "    # https://keras.io\n",
    "    # https://keras.io/layers/core/\n",
    "    # https://keras.io/losses/\n",
    "    # https://keras.io/optimizers/\n",
    "\n",
    "    # Optimization\n",
    "    # Error function: mean squared error\n",
    "    # Optimizers:\n",
    "    # SGD - stochastic gradient descent\n",
    "    # RMSprop\n",
    "    # Adagrad - Adaptive gradient\n",
    "    # Adadelta\n",
    "    # Adam - Adaptive Moment Estimation\n",
    "    # Adamax\n",
    "    # Nadam - Nesterov Adam optimizer\n",
    "\n",
    "    # Activation Functions\n",
    "    # softmax\n",
    "    # elu - Exponential Linear Unit\n",
    "    # selu - Scaled Exponential Linear Unit\n",
    "    # softplus\n",
    "    # softsign\n",
    "    # relu - rectified linear unit\n",
    "    # tanh - hyperbolic tangent\n",
    "    # sigmoid\n",
    "    # hard_sigmoid\n",
    "    # linear\n",
    "\n",
    "    num_neurons_1 = x_train.shape[1];\n",
    "    num_neurons_2 = round(x_train.shape[1]/2);\n",
    "    num_neurons_3 = round(x_train.shape[1]/4);\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_neurons_1, input_dim=x_train.shape[1], activation=activ_func))\n",
    "    model.add(Dense(num_neurons_2, activation=activ_func))\n",
    "    model.add(Dense(num_neurons_3, activation=activ_func))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=learn_algo)\n",
    "    \n",
    "    # Learning Algorithm monitor: Stop training when\n",
    "    # validation loss is less the 1e-3 5 times in a row\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=0, mode='auto')\n",
    "    \n",
    "    # Save weights for NN\n",
    "    checkpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\", verbose=0, save_best_only=True)\n",
    "    \n",
    "    # Train NN\n",
    "    # epochs=1000, Epoch: # complete iterations of the data set to be learned\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=0,epochs=3000)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model_layer_3(x_train, y_train, x_test, y_test, activ_func, learn_algo):\n",
    "    # Create the Neural Network Model\n",
    "    # Squential Network with up to 3 layers.\n",
    "    # Layer 1: nFeatures nodes using the rectifier\n",
    "    # Layer n: 1 node (regression)\n",
    "    # NN using optimization adam\n",
    "\n",
    "    # https://keras.io\n",
    "    # https://keras.io/layers/core/\n",
    "    # https://keras.io/losses/\n",
    "    # https://keras.io/optimizers/\n",
    "\n",
    "    # Optimization\n",
    "    # Error function: mean squared error\n",
    "    # Optimizers:\n",
    "    # SGD - stochastic gradient descent\n",
    "    # RMSprop\n",
    "    # Adagrad - Adaptive gradient\n",
    "    # Adadelta\n",
    "    # Adam - Adaptive Moment Estimation\n",
    "    # Adamax\n",
    "    # Nadam - Nesterov Adam optimizer\n",
    "\n",
    "    # Activation Functions\n",
    "    # softmax\n",
    "    # elu - Exponential Linear Unit\n",
    "    # selu - Scaled Exponential Linear Unit\n",
    "    # softplus\n",
    "    # softsign\n",
    "    # relu - rectified linear unit\n",
    "    # tanh - hyperbolic tangent\n",
    "    # sigmoid\n",
    "    # hard_sigmoid\n",
    "    # linear\n",
    "\n",
    "    num_neurons_1 = x_train.shape[1];\n",
    "    num_neurons_2 = round(x_train.shape[1]/2);\n",
    "    num_neurons_3 = round(x_train.shape[1]/4);\n",
    "    num_neurons_4 = round(x_train.shape[1]/8);\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_neurons_1, input_dim=x_train.shape[1], activation=activ_func))\n",
    "    model.add(Dense(num_neurons_2, activation=activ_func))\n",
    "    model.add(Dense(num_neurons_3, activation=activ_func))\n",
    "    model.add(Dense(num_neurons_4, activation=activ_func))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=learn_algo)\n",
    "    \n",
    "    # Learning Algorithm monitor: Stop training when\n",
    "    # validation loss is less the 1e-3 5 times in a row\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=0, mode='auto')\n",
    "    \n",
    "    # Save weights for NN\n",
    "    checkpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\", verbose=0, save_best_only=True)\n",
    "    \n",
    "    # Train NN\n",
    "    # epochs=1000, Epoch: # complete iterations of the data set to be learned\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=0,epochs=3000)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_plot(pred, y_test): \n",
    "    errors = []\n",
    "    for index in range(len(pred)):\n",
    "        try:\n",
    "            errors.append(pred[index][0] - y_test[y_test.index[index]])\n",
    "        except KeyError:\n",
    "            pass\n",
    "             # If we get a key error then we can't compare the prediction and error so we should just continue \n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.title('Neural Net Results')\n",
    "    plt.xlabel('Salary Prediction Error')\n",
    "    plt.ylabel('Count')\n",
    "    plt.hist(errors, bins=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_prediction(model, x_test, y_test):    \n",
    "    # load weights from Training NN\n",
    "    model.load_weights('best_weights.hdf5') \n",
    "\n",
    "    # Run Prediction\n",
    "    pred = model.predict(x_test)\n",
    "\n",
    "     # Calculate RMS\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    \n",
    "    # Histogram Plot\n",
    "    #hist_plot(pred, y_test)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ten_fold_rmsd(df, activ_func, learn_algo):\n",
    "    rmse_sum_1 = 0\n",
    "    rmse_sum_2 = 0\n",
    "    rmse_sum_3 = 0\n",
    "    \n",
    "    fold=10;\n",
    "    for i in range(fold):\n",
    "        print(\"Iterator {}\".format(i))\n",
    "        # 1/10 of Dataset\n",
    "        test = df.iloc[int(len(df) * i/fold): int(len(df) * (i+1)/fold)]\n",
    "        \n",
    "        # Seperate Data into train and test\n",
    "        train = df.drop(test.index)\n",
    "\n",
    "        # Seperate targets\n",
    "        x_train = train.drop(columns='Salary')\n",
    "        y_train = train['Salary']\n",
    "        x_test = test.drop(columns='Salary')\n",
    "        y_test = test['Salary']\n",
    "        \n",
    "        # Create NN Models with 1 layer\n",
    "        rms = 0;\n",
    "        model_1 = nn_model_layer_1(x_train, y_train, x_test, y_test, activ_func, learn_algo)\n",
    "        \n",
    "        # Prediction\n",
    "        rms = nn_prediction(model_1, x_test, y_test)\n",
    "        print(\"Layer 1 RMS: {}\".format(rms))\n",
    "\n",
    "        # Delete Model\n",
    "        os.remove(\"best_weights.hdf5\")\n",
    "        del model_1\n",
    "\n",
    "        rmse_sum_1 += rms\n",
    "        \n",
    "        # Create NN Models with 2 layer\n",
    "        rms = 0;\n",
    "        model_2 = nn_model_layer_2(x_train, y_train, x_test, y_test, activ_func, learn_algo)\n",
    "        \n",
    "        # Prediction\n",
    "        rms = nn_prediction(model_2, x_test, y_test)\n",
    "        print(\"Layer 2 RMS: {}\".format(rms))\n",
    "\n",
    "        # Delete Model\n",
    "        os.remove(\"best_weights.hdf5\")\n",
    "        del model_2\n",
    "\n",
    "        rmse_sum_2 += rms\n",
    "        \n",
    "        # Create NN Models with 3 layer\n",
    "        rms = 0;\n",
    "        model_3 = nn_model_layer_3(x_train, y_train, x_test, y_test, activ_func, learn_algo)\n",
    "        \n",
    "        # Prediction\n",
    "        rms = nn_prediction(model_3, x_test, y_test)\n",
    "        print(\"Layer 3 RMS: {}\".format(rms))\n",
    "\n",
    "        # Delete Model\n",
    "        os.remove(\"best_weights.hdf5\")\n",
    "        del model_3\n",
    "\n",
    "        rmse_sum_3 += rms\n",
    "        \n",
    "        \n",
    "        \n",
    "    print(\"\\nAverage Layer 1 RMS: {}\".format(rmse_sum_1/10))\n",
    "    print(\"\\nAverage Layer 2 RMS: {}\".format(rmse_sum_2/10))\n",
    "    print(\"\\nAverage Layer 3 RMS: {}\".format(rmse_sum_3/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Algorithm: Adam\n",
      "Activiation Function: Linear\n",
      "Iterator 0\n",
      "Layer 1 RMS: 19731.688081477812\n",
      "Layer 2 RMS: 19622.20715867903\n",
      "Layer 3 RMS: 19705.989239303803\n",
      "Iterator 1\n",
      "Layer 1 RMS: 19140.62221988296\n",
      "Layer 2 RMS: 19234.274935468296\n",
      "Layer 3 RMS: 19428.77988519977\n",
      "Iterator 2\n",
      "Layer 1 RMS: 19272.05299882932\n",
      "Layer 2 RMS: 19452.709235544717\n",
      "Layer 3 RMS: 19455.33386322792\n",
      "Iterator 3\n",
      "Layer 1 RMS: 19477.55312534022\n",
      "Layer 2 RMS: 19567.484281653145\n",
      "Layer 3 RMS: 19452.64803338501\n",
      "Iterator 4\n",
      "Layer 1 RMS: 20785.44855320966\n",
      "Layer 2 RMS: 20712.963248028616\n",
      "Layer 3 RMS: 20846.683746201663\n",
      "Iterator 5\n",
      "Layer 1 RMS: 18911.33668231608\n",
      "Layer 2 RMS: 18955.859245673077\n",
      "Layer 3 RMS: 19128.18069336035\n",
      "Iterator 6\n",
      "Layer 1 RMS: 19738.777279092614\n",
      "Layer 2 RMS: 19709.652962341355\n",
      "Layer 3 RMS: 19758.862239527807\n",
      "Iterator 7\n",
      "Layer 1 RMS: 20487.359683847837\n",
      "Layer 2 RMS: 20475.610430911733\n",
      "Layer 3 RMS: 20554.7246806619\n",
      "Iterator 8\n",
      "Layer 1 RMS: 19565.78559317298\n",
      "Layer 2 RMS: 19668.38976590078\n",
      "Layer 3 RMS: 19604.162485090736\n",
      "Iterator 9\n",
      "Layer 1 RMS: 18127.512164456853\n",
      "Layer 2 RMS: 18322.297325214113\n",
      "Layer 3 RMS: 18226.452613431935\n",
      "\n",
      "Average Layer 1 RMS: 19523.813638162632\n",
      "\n",
      "Average Layer 2 RMS: 19572.144858941487\n",
      "\n",
      "Average Layer 3 RMS: 19616.18174793909\n"
     ]
    }
   ],
   "source": [
    "print(\"Learning Algorithm: Adam\")\n",
    "print(\"Activiation Function: Linear\")\n",
    "ten_fold_rmsd(df, 'linear', 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Algorithm: Adam\n",
      "Activiation Function: Rectified Linear Unit\n",
      "Iterator 0\n",
      "Layer 1 RMS: 18710.071351335537\n",
      "Layer 2 RMS: 18822.931447901956\n",
      "Layer 3 RMS: 18946.085649538265\n",
      "Iterator 1\n",
      "Layer 1 RMS: 18283.759152299735\n",
      "Layer 2 RMS: 18428.946816146236\n",
      "Layer 3 RMS: 18802.66641813544\n",
      "Iterator 2\n",
      "Layer 1 RMS: 18293.9187924753\n",
      "Layer 2 RMS: 18370.134299926\n",
      "Layer 3 RMS: 18696.827042505687\n",
      "Iterator 3\n",
      "Layer 1 RMS: 18570.73908959993\n",
      "Layer 2 RMS: 18788.785401175963\n",
      "Layer 3 RMS: 18795.998531903693\n",
      "Iterator 4\n",
      "Layer 1 RMS: 19502.51574238027\n",
      "Layer 2 RMS: 19662.15801136197\n",
      "Layer 3 RMS: 19829.02398881795\n",
      "Iterator 5\n",
      "Layer 1 RMS: 18219.146360138955\n",
      "Layer 2 RMS: 18323.6443294008\n",
      "Layer 3 RMS: 18242.88036872133\n",
      "Iterator 6\n",
      "Layer 1 RMS: 18574.545123552856\n",
      "Layer 2 RMS: 18883.3712848089\n",
      "Layer 3 RMS: 18910.75904540993\n",
      "Iterator 7\n",
      "Layer 1 RMS: 19641.052724931378\n",
      "Layer 2 RMS: 19911.286102833445\n",
      "Layer 3 RMS: 19997.15832777363\n",
      "Iterator 8\n",
      "Layer 1 RMS: 18481.071203125844\n",
      "Layer 2 RMS: 18518.279392770022\n",
      "Layer 3 RMS: 18701.12456666153\n",
      "Iterator 9\n",
      "Layer 1 RMS: 17719.799850465886\n",
      "Layer 2 RMS: 17872.398177568015\n",
      "Layer 3 RMS: 17862.449956680044\n",
      "\n",
      "Average Layer 1 RMS: 18599.661939030568\n",
      "\n",
      "Average Layer 2 RMS: 18758.193526389332\n",
      "\n",
      "Average Layer 3 RMS: 18878.49738961475\n"
     ]
    }
   ],
   "source": [
    "print(\"Learning Algorithm: Adam\")\n",
    "print(\"Activiation Function: Rectified Linear Unit\")\n",
    "ten_fold_rmsd(df, 'relu', 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Algorithm: Adam\n",
      "Activiation Function: Softplus\n",
      "Iterator 0\n",
      "Layer 1 RMS: 18726.78555172822\n",
      "Layer 2 RMS: 18838.472115928\n",
      "Layer 3 RMS: 18902.576268838475\n",
      "Iterator 1\n",
      "Layer 1 RMS: 18329.92277366763\n",
      "Layer 2 RMS: 18338.644704702187\n",
      "Layer 3 RMS: 18210.83604100455\n",
      "Iterator 2\n",
      "Layer 1 RMS: 18547.1609390065\n",
      "Layer 2 RMS: 18563.36364914337\n",
      "Layer 3 RMS: 18336.400252454263\n",
      "Iterator 3\n",
      "Layer 1 RMS: 18556.63414097373\n",
      "Layer 2 RMS: 18722.363168436674\n",
      "Layer 3 RMS: 18672.30098030077\n",
      "Iterator 4\n",
      "Layer 1 RMS: 19462.175834233585\n",
      "Layer 2 RMS: 19487.784648416735\n",
      "Layer 3 RMS: 19656.28209130081\n",
      "Iterator 5\n",
      "Layer 1 RMS: 18239.24792434996\n",
      "Layer 2 RMS: 18242.743663844798\n",
      "Layer 3 RMS: 18179.090588604053\n",
      "Iterator 6\n",
      "Layer 1 RMS: 18609.672486257754\n",
      "Layer 2 RMS: 18777.900911408466\n",
      "Layer 3 RMS: 18814.818636578675\n",
      "Iterator 7\n",
      "Layer 1 RMS: 19763.389524041002\n",
      "Layer 2 RMS: 19846.884002125036\n",
      "Layer 3 RMS: 19825.84772381454\n",
      "Iterator 8\n",
      "Layer 1 RMS: 18513.240156947162\n",
      "Layer 2 RMS: 18579.929216844874\n",
      "Layer 3 RMS: 18622.83110434905\n",
      "Iterator 9\n",
      "Layer 1 RMS: 17693.06201823043\n",
      "Layer 2 RMS: 17823.785823842976\n",
      "Layer 3 RMS: 17827.922441295817\n",
      "\n",
      "Average Layer 1 RMS: 18644.1291349436\n",
      "\n",
      "Average Layer 2 RMS: 18722.18719046931\n",
      "\n",
      "Average Layer 3 RMS: 18704.890612854102\n"
     ]
    }
   ],
   "source": [
    "print(\"Learning Algorithm: Adam\")\n",
    "print(\"Activiation Function: Softplus\")\n",
    "ten_fold_rmsd(df, 'softplus', 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Algorithm: RMSprop\n",
      "Activiation Function: Linear\n",
      "Iterator 0\n",
      "Layer 1 RMS: 19648.974700567076\n",
      "Layer 2 RMS: 19524.71790786219\n",
      "Layer 3 RMS: 20169.115556102668\n",
      "Iterator 1\n",
      "Layer 1 RMS: 19101.501996717492\n",
      "Layer 2 RMS: 19210.54900433813\n",
      "Layer 3 RMS: 19338.044629655655\n",
      "Iterator 2\n",
      "Layer 1 RMS: 19318.535511204438\n",
      "Layer 2 RMS: 19355.71144467515\n",
      "Layer 3 RMS: 19925.890452630123\n",
      "Iterator 3\n",
      "Layer 1 RMS: 19270.697948592733\n",
      "Layer 2 RMS: 19571.258279410697\n",
      "Layer 3 RMS: 19570.170495980678\n",
      "Iterator 4\n",
      "Layer 1 RMS: 20807.183972231716\n",
      "Layer 2 RMS: 21378.02772445304\n",
      "Layer 3 RMS: 20878.161852491354\n",
      "Iterator 5\n",
      "Layer 1 RMS: 19100.055694750554\n",
      "Layer 2 RMS: 19269.459906703512\n",
      "Layer 3 RMS: 19117.987552344293\n",
      "Iterator 6\n",
      "Layer 1 RMS: 19648.99782968185\n",
      "Layer 2 RMS: 19655.63479890603\n",
      "Layer 3 RMS: 19662.665844199117\n",
      "Iterator 7\n",
      "Layer 1 RMS: 20590.18428211776\n",
      "Layer 2 RMS: 20804.380417081455\n",
      "Layer 3 RMS: 20602.961069420908\n",
      "Iterator 8\n",
      "Layer 1 RMS: 19573.08263935931\n",
      "Layer 2 RMS: 19755.10668543882\n",
      "Layer 3 RMS: 19858.210377510415\n",
      "Iterator 9\n",
      "Layer 1 RMS: 18212.710156262023\n",
      "Layer 2 RMS: 18184.134962669264\n",
      "Layer 3 RMS: 18919.57461432321\n",
      "\n",
      "Average Layer 1 RMS: 19527.192473148498\n",
      "\n",
      "Average Layer 2 RMS: 19670.89811315383\n",
      "\n",
      "Average Layer 3 RMS: 19804.27824446584\n"
     ]
    }
   ],
   "source": [
    "print(\"Learning Algorithm: RMSprop\")\n",
    "print(\"Activiation Function: Linear\")\n",
    "ten_fold_rmsd(df, 'linear', 'RMSprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Algorithm: RMSprop\n",
      "Activiation Function: Rectified Linear Unit\n",
      "Iterator 0\n",
      "Layer 1 RMS: 18815.133200045275\n",
      "Layer 2 RMS: 18840.995041936098\n",
      "Layer 3 RMS: 18822.507656447237\n",
      "Iterator 1\n",
      "Layer 1 RMS: 18137.329998698162\n",
      "Layer 2 RMS: 18335.472639531697\n",
      "Layer 3 RMS: 18352.849077233936\n",
      "Iterator 2\n",
      "Layer 1 RMS: 18375.990762660276\n",
      "Layer 2 RMS: 18624.016645275013\n",
      "Layer 3 RMS: 18479.330480269724\n",
      "Iterator 3\n",
      "Layer 1 RMS: 18548.852333632247\n",
      "Layer 2 RMS: 18741.279260109462\n",
      "Layer 3 RMS: 18729.032236086114\n",
      "Iterator 4\n",
      "Layer 1 RMS: 19434.554253507933\n",
      "Layer 2 RMS: 19695.357051138897\n",
      "Layer 3 RMS: 19844.470750452074\n",
      "Iterator 5\n",
      "Layer 1 RMS: 18240.812010831138\n",
      "Layer 2 RMS: 18277.376910825322\n",
      "Layer 3 RMS: 18546.92720928119\n",
      "Iterator 6\n",
      "Layer 1 RMS: 18575.89363071156\n",
      "Layer 2 RMS: 18752.954771979857\n",
      "Layer 3 RMS: 19180.960399921372\n",
      "Iterator 7\n",
      "Layer 1 RMS: 19833.69296444045\n",
      "Layer 2 RMS: 19765.63488611924\n",
      "Layer 3 RMS: 19976.137345714273\n",
      "Iterator 8\n",
      "Layer 1 RMS: 18366.65367924489\n",
      "Layer 2 RMS: 18536.971807215665\n",
      "Layer 3 RMS: 18643.512225411247\n",
      "Iterator 9\n",
      "Layer 1 RMS: 17918.20972671307\n",
      "Layer 2 RMS: 18064.849135422824\n",
      "Layer 3 RMS: 18201.635850808914\n",
      "\n",
      "Average Layer 1 RMS: 18624.7122560485\n",
      "\n",
      "Average Layer 2 RMS: 18763.490814955403\n",
      "\n",
      "Average Layer 3 RMS: 18877.736323162608\n"
     ]
    }
   ],
   "source": [
    "print(\"Learning Algorithm: RMSprop\")\n",
    "print(\"Activiation Function: Rectified Linear Unit\")\n",
    "ten_fold_rmsd(df, 'relu', 'RMSprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Algorithm: RMSprop\n",
      "Activiation Function: Softplus\n",
      "Iterator 0\n",
      "Layer 1 RMS: 18659.169552135383\n",
      "Layer 2 RMS: 18691.872223991537\n",
      "Layer 3 RMS: 19053.00980838829\n",
      "Iterator 1\n",
      "Layer 1 RMS: 18150.71627498358\n",
      "Layer 2 RMS: 18170.51955026183\n",
      "Layer 3 RMS: 18500.109851999467\n",
      "Iterator 2\n",
      "Layer 1 RMS: 18252.78762856522\n",
      "Layer 2 RMS: 18230.45280470838\n",
      "Layer 3 RMS: 18504.905980478085\n",
      "Iterator 3\n",
      "Layer 1 RMS: 18506.89984639659\n",
      "Layer 2 RMS: 18588.673372211728\n",
      "Layer 3 RMS: 18788.079244109136\n",
      "Iterator 4\n",
      "Layer 1 RMS: 19472.655739883965\n",
      "Layer 2 RMS: 19459.63726089353\n",
      "Layer 3 RMS: 19516.39975967971\n",
      "Iterator 5\n",
      "Layer 1 RMS: 18125.954403720112\n",
      "Layer 2 RMS: 18083.99212858747\n",
      "Layer 3 RMS: 18072.692128083032\n",
      "Iterator 6\n",
      "Layer 1 RMS: 18475.05596947313\n",
      "Layer 2 RMS: 18730.392520987916\n",
      "Layer 3 RMS: 18736.45624342756\n",
      "Iterator 7\n",
      "Layer 1 RMS: 19785.25314093745\n",
      "Layer 2 RMS: 19782.878525310636\n",
      "Layer 3 RMS: 19783.76152643248\n",
      "Iterator 8\n",
      "Layer 1 RMS: 18314.674916717504\n",
      "Layer 2 RMS: 18522.860545518524\n",
      "Layer 3 RMS: 18827.445776019835\n",
      "Iterator 9\n",
      "Layer 1 RMS: 17880.68511948837\n",
      "Layer 2 RMS: 17841.03698002082\n",
      "Layer 3 RMS: 18146.647340495685\n",
      "\n",
      "Average Layer 1 RMS: 18562.38525923013\n",
      "\n",
      "Average Layer 2 RMS: 18610.231591249238\n",
      "\n",
      "Average Layer 3 RMS: 18792.950765911326\n"
     ]
    }
   ],
   "source": [
    "print(\"Learning Algorithm: RMSprop\")\n",
    "print(\"Activiation Function: Softplus\")\n",
    "ten_fold_rmsd(df, 'softplus', 'RMSprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Algorithm: Adam\n",
      "Activiation Function: Sigmoid\n",
      "Iterator 0\n",
      "Layer 1 RMS: 33177.65164640799\n",
      "Layer 2 RMS: 41336.42739897715\n",
      "Layer 3 RMS: 51319.38159151163\n",
      "Iterator 1\n",
      "Layer 1 RMS: 30924.394677252298\n",
      "Layer 2 RMS: 41833.56729977633\n",
      "Layer 3 RMS: 51564.657142539836\n",
      "Iterator 2\n",
      "Layer 1 RMS: 30512.69567724191\n",
      "Layer 2 RMS: 42127.08273381581\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-9ed57f1b4c10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Learning Algorithm: Adam\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Activiation Function: Sigmoid\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mten_fold_rmsd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'adam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-72-b5e747d02dac>\u001b[0m in \u001b[0;36mten_fold_rmsd\u001b[1;34m(df, activ_func, learn_algo)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;31m# Create NN Models with 3 layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mrms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mmodel_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn_model_layer_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactiv_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearn_algo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;31m# Prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-69-9dc59c4e1cd8>\u001b[0m in \u001b[0;36mnn_model_layer_3\u001b[1;34m(x_train, y_train, x_test, y_test, activ_func, learn_algo)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;31m# Train NN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;31m# epochs=1000, Epoch: # complete iterations of the data set to be learned\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fr23505\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\fr23505\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\fr23505\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fr23505\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fr23505\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fr23505\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fr23505\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fr23505\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fr23505\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fr23505\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Learning Algorithm: Adam\")\n",
    "print(\"Activiation Function: Sigmoid\")\n",
    "ten_fold_rmsd(df, 'sigmoid', 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Learning Algorithm: RMSprop\")\n",
    "print(\"Activiation Function: Sigmoid\")\n",
    "ten_fold_rmsd(df, 'sigmoid', 'RMSprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Algorithm: Adam\n",
      "Activiation Function: Linear\n",
      "Iterator 0\n",
      "Layer 1 RMS: 21310.215900741576\n",
      "Layer 2 RMS: 21297.564766865366\n",
      "Layer 3 RMS: 21347.56136511836\n",
      "Iterator 1\n",
      "Layer 1 RMS: 21049.277888517365\n",
      "Layer 2 RMS: 21028.178582074634\n",
      "Layer 3 RMS: 21025.437289975962\n",
      "Iterator 2\n",
      "Layer 1 RMS: 21277.699153704074\n",
      "Layer 2 RMS: 21295.91386093724\n",
      "Layer 3 RMS: 21296.414916608515\n",
      "Iterator 3\n",
      "Layer 1 RMS: 21700.241583161416\n",
      "Layer 2 RMS: 21690.87526511951\n",
      "Layer 3 RMS: 21685.030334169613\n",
      "Iterator 4\n",
      "Layer 1 RMS: 22910.319023690714\n",
      "Layer 2 RMS: 22870.959925767544\n",
      "Layer 3 RMS: 22906.674536952996\n",
      "Iterator 5\n",
      "Layer 1 RMS: 21441.763914674168\n",
      "Layer 2 RMS: 21442.77922468516\n",
      "Layer 3 RMS: 21429.600235494876\n",
      "Iterator 6\n",
      "Layer 1 RMS: 21416.949694892406\n",
      "Layer 2 RMS: 21407.508530486055\n",
      "Layer 3 RMS: 21406.337169514813\n",
      "Iterator 7\n",
      "Layer 1 RMS: 22480.729396755225\n",
      "Layer 2 RMS: 22470.243830555788\n",
      "Layer 3 RMS: 22507.727455847238\n",
      "Iterator 8\n",
      "Layer 1 RMS: 22071.846592918457\n",
      "Layer 2 RMS: 22093.754058142684\n",
      "Layer 3 RMS: 22096.977124027002\n",
      "Iterator 9\n",
      "Layer 1 RMS: 20530.37441405298\n",
      "Layer 2 RMS: 20576.128805252883\n",
      "Layer 3 RMS: 20517.093924791516\n",
      "\n",
      "Average Layer 1 RMS: 21618.941756310836\n",
      "\n",
      "Average Layer 2 RMS: 21617.390684988688\n",
      "\n",
      "Average Layer 3 RMS: 21621.88543525009\n"
     ]
    }
   ],
   "source": [
    "# Use Dimensional Reduced dataset\n",
    "print(\"Learning Algorithm: Adam\")\n",
    "print(\"Activiation Function: Linear\")\n",
    "ten_fold_rmsd(dfr, 'linear', 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram Plot\n",
    "print(\"Learning Algorithm: Adam\")\n",
    "print(\"Activiation Function: Linear\")\n",
    "ten_fold_rmsd(df, 'linear', 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
